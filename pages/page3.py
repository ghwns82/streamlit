# app_webrtc_every2s.py
import time
import threading
from typing import Any, Dict, Optional

import cv2
import av
import requests
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, VideoProcessorBase

st.set_page_config(page_title="ì‹¤ì‹œê°„ ì–¼êµ´ ì‹ë³„ (2ì´ˆ ì£¼ê¸°)", page_icon="ğŸ§‘â€ğŸ’¼")
st.title("ğŸ§‘â€ğŸ’¼ ì‹¤ì‹œê°„ ì–¼êµ´ ì‹ë³„")
st.caption("ì‹¤ì‹œê°„ ì¹´ë©”ë¼ë¥¼ í‘œì‹œí•˜ê³ , ì •í™•íˆ 2ì´ˆë§ˆë‹¤ FastAPIë¡œ í”„ë ˆì„ì„ ì „ì†¡í•©ë‹ˆë‹¤.")

# ë„¤ê°€ ì“°ë˜ ìŠ¤íƒ€ì¼ì— ë§ì¶° ìƒìˆ˜ë¡œ ë‘ 
RECOGNITION_API = st.text_input(
    "FastAPI ì—”ë“œí¬ì¸íŠ¸",
    value="https://fastapi-3uqk.onrender.com/predict",
    help="POST multipart/form-data ë¡œ file=ì´ë¯¸ì§€ ì „ì†¡",
)
show_raw = st.checkbox("ì„œë²„ ì›ë³¸ ì‘ë‹µ(JSON) í‘œì‹œ", value=False)

# ìµœì‹  ì‘ë‹µ íŒ¨ë„(ê³„ì† ìœ ì§€)
result_box = st.empty()
raw_box = st.empty()

def _safe_parse_label(data: Any) -> str:
    """
    ë„¤ê°€ ì¤€ ë¡œì§ì„ ì¡´ì¤‘:
    - data.get('predictions', {})ì—ì„œ 'ResNet18' í‚¤ë¥¼ ìš°ì„  ì‚¬ìš©
    - ì—†ìœ¼ë©´ name/id/identity ë“±ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„
    - ì „í˜€ ì—†ìœ¼ë©´ 'Unknown'
    """
    try:
        if isinstance(data, dict):
            preds = data.get("predictions", {})
            if isinstance(preds, dict):
                label = preds.get("ResNet18")
                if label:
                    return str(label)

            # ë‹¨ì¼ ê²°ê³¼ íƒ€ì… ëŒ€ì‘
            for k in ("name", "id", "identity", "label"):
                if k in data and data[k]:
                    return str(data[k])

            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœ predictions ëŒ€ì‘
            if isinstance(preds, list) and preds:
                cand = preds[0]
                if isinstance(cand, dict):
                    for k in ("name", "identity", "id", "label"):
                        if k in cand and cand[k]:
                            return str(cand[k])
        return "Unknown"
    except Exception:
        return "Unknown"

class VideoProcessor(VideoProcessorBase):
    def __init__(self):
        self.frame_count = 0
        self.result_label = "..."
        self.request_interval = 2.0   # âœ… ì •í™•íˆ 2ì´ˆ ê°„ê²©(ì´ˆ)
        self.last_sent_ts = 0.0
        self.lock = threading.Lock()
        self.last_json: Optional[Dict] = None

    def send_frame_to_backend(self, img):
        try:
            ok, img_encoded = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
            if not ok:
                label = "Error"
            else:
                response = requests.post(
                    RECOGNITION_API,
                    files={"file": ("frame.jpg", img_encoded.tobytes(), "image/jpeg")},
                    timeout=10,  # âœ… ë„‰ë„‰í•œ íƒ€ì„ì•„ì›ƒ
                )
                if response.status_code == 200:
                    data = response.json()
                    label = _safe_parse_label(data)
                else:
                    data = {"error": f"HTTP {response.status_code}", "text": response.text}
                    label = "Error"
        except Exception as e:
            # ì½˜ì†”ì— ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥(ë„¤ê°€ í•˜ë˜ ê²ƒ ìœ ì§€)
            print("ğŸ”¥ ì˜ˆì™¸ ë°œìƒ:", e)
            data = {"error": "network", "message": str(e)}
            label = "Error"

        # ê²°ê³¼ ì—…ë°ì´íŠ¸
        with self.lock:
            self.result_label = label
            self.last_json = data

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        self.frame_count += 1

        # âœ… í”„ë ˆì„ ì¹´ìš´íŠ¸ ëŒ€ì‹  'ì‹œê°„' ê¸°ì¤€ ìŠ¤ë¡œí‹€ë§ (ì •í™•íˆ 2ì´ˆë§ˆë‹¤)
        now = time.time()
        if now - self.last_sent_ts >= self.request_interval and RECOGNITION_API:
            self.last_sent_ts = now
            threading.Thread(target=self.send_frame_to_backend, args=(img.copy(),), daemon=True).start()

        # í˜„ì¬ ë¼ë²¨ì„ í”„ë ˆì„ì— ì˜¤ë²„ë ˆì´
        with self.lock:
            label_to_display = self.result_label

        cv2.putText(img, label_to_display, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# WebRTC: ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í‘œì‹œ
ctx = webrtc_streamer(
    key="face-recognition",
    mode=WebRtcMode.SENDRECV,
    media_stream_constraints={"video": True, "audio": False},
    video_processor_factory=VideoProcessor,
    async_processing=True,
)

# ===== ìš°ì¸¡ íŒ¨ë„ì— ìµœì‹  ì‘ë‹µì„ 'ê³„ì†' í‘œì‹œ (ìƒˆ ì‘ë‹µ ì˜¤ë©´ ì¦‰ì‹œ ê°±ì‹ ) =====
# autorefreshë¡œ ê°€ë³ê²Œ ê°±ì‹ (0.5ì´ˆë§ˆë‹¤)
st.autorefresh(interval=500, key="live_refresh")

if ctx and ctx.video_processor:
    with ctx.video_processor.lock:
        current_label = ctx.video_processor.result_label
        current_json = ctx.video_processor.last_json

    # ë¼ë²¨ì€ í•­ìƒ í‘œì‹œ(ê³„ì† ìœ ì§€)
    if current_label and current_label != "...":
        result_box.success(f"í˜„ì¬ ê²°ê³¼: **{current_label}**")
    else:
        result_box.info("í˜„ì¬ ê²°ê³¼ ëŒ€ê¸° ì¤‘... (2ì´ˆë§ˆë‹¤ ì „ì†¡)")

    # ì›ë³¸ JSON ì˜µì…˜
    if show_raw:
        raw_box.subheader("Raw Response")
        if current_json is not None:
            raw_box.json(current_json)
        else:
            raw_box.write({"info": "ì•„ì§ ì‘ë‹µ ì—†ìŒ"})
else:
    result_box.info("ì¹´ë©”ë¼ ê¶Œí•œì„ í—ˆìš©í•˜ë©´ ì‹¤ì‹œê°„ í™”ë©´ì´ í‘œì‹œë©ë‹ˆë‹¤.")
    raw_box.empty()
